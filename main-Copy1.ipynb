{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IF702 Redes Neurais\n",
    "Este notebook contém um script base para o projeto da disciplina IF702 Redes Neurais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('nbagg')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura e Limpeza dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A leitura dos dados é feita utilizando a biblioteca `pandas`. O presente exemplo importa a base de dados `mammography`. Caso você esteja trabalhando com outro data set, modifique este trecho de código.\n",
    "Para importar o conjunto de dados do PAKDD, use a função `pd.read_table` ao invés da `pd.read_csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             X1        X2        X3        X4        X5  class\n",
      "0      0.230020  5.072578 -0.276061  0.832444 -0.377866     -1\n",
      "1      0.155491 -0.169390  0.670652 -0.859553 -0.377866     -1\n",
      "2     -0.784415 -0.443654  5.674705 -0.859553 -0.377866     -1\n",
      "3      0.546088  0.131415 -0.456387 -0.859553 -0.377866     -1\n",
      "4     -0.102987 -0.394994 -0.140816  0.979703 -0.377866     -1\n",
      "5     -0.180395 -0.381723  0.264918  0.772950  1.468981     -1\n",
      "6     -0.068603 -0.346334 -0.185897  0.899111  1.743381     -1\n",
      "7     -0.082492 -0.448077  0.896060 -0.859553 -0.377866     -1\n",
      "8     -0.151600 -0.368452  0.625571  1.197426 -0.377866     -1\n",
      "9     -0.784415 -0.470195 -0.591631 -0.859553 -0.377866     -1\n",
      "10    -0.081137 -0.324216  1.031305  1.171687 -0.377866     -1\n",
      "11    -0.784415 -0.470195 -0.591631 -0.859553 -0.377866     -1\n",
      "12     0.775094 -0.443654 -0.501468 -0.859553 -0.377866     -1\n",
      "13     0.537619  1.586780 -0.276061  2.375494 -0.377866     -1\n",
      "14     1.304077  1.060371 -0.366224  1.865364 -0.377866     -1\n",
      "15     0.386021  1.776995 -0.411305  0.769574 -0.377866     -1\n",
      "16    -0.784415 -0.470195 -0.591631 -0.859553 -0.377866     -1\n",
      "17    -0.101124 -0.279980 -0.276061 -0.859553 -0.377866     -1\n",
      "18     7.469616 -0.448077 -0.591631 -0.859553 -0.377866     -1\n",
      "19    -0.784415 -0.470195 -0.591631 -0.859553 -0.377866     -1\n",
      "20     0.815068  2.728069 -0.050653  0.629911  0.791016     -1\n",
      "21     0.764084  0.569351 -0.501468  1.378018 -0.377866     -1\n",
      "22    -0.442261 -0.443654  1.437039 -0.194146  0.127044     -1\n",
      "23    -0.784415 -0.470195 -0.591631 -0.859553 -0.377866     -1\n",
      "24    -0.784415 -0.470195 -0.591631 -0.859553 -0.377866     -1\n",
      "25    -0.784415 -0.470195 -0.591631 -0.859553 -0.377866     -1\n",
      "26    -0.784415 -0.470195 -0.591631 -0.859553 -0.377866     -1\n",
      "27     0.601646  0.600316  0.310000  0.885609  0.728063     -1\n",
      "28     0.145159 -0.173814 -0.185897  0.545100 -0.377866     -1\n",
      "29    -0.295406 -0.412689  0.039510 -0.859553 -0.377866     -1\n",
      "...         ...       ...       ...       ...       ...    ...\n",
      "11153 -0.784415 -0.470195 -0.591631 -0.859553 -0.377866     -1\n",
      "11154  0.151934 -0.213626 -0.005571  0.423158 -0.377866     -1\n",
      "11155 -0.784415 -0.470195 -0.591631 -0.859553 -0.377866     -1\n",
      "11156  0.185303  0.945357  0.084592  0.837929 -0.377866     -1\n",
      "11157 -0.012537 -0.421536  0.400163  1.218101  1.080463      1\n",
      "11158  1.241744  4.205552 -0.321142  1.365782  1.829349      1\n",
      "11159  0.754260  0.016401  0.084592  4.942182  1.421602      1\n",
      "11160  0.964125 -0.341911 -0.411305  1.574222  3.703261      1\n",
      "11161 -0.784415 -0.470195 -0.591631 -0.859553 -0.377866      1\n",
      "11162  0.602662 -0.076495 -0.456387  1.844688  3.068362      1\n",
      "11163  0.187674 -0.328640 -0.456387  1.405444  4.605053      1\n",
      "11164  0.202580 -0.412689 -0.321142  1.223586  2.964186      1\n",
      "11165  1.107254 -0.098613 -0.546550  1.709666  7.722192      1\n",
      "11166  0.560655 -0.368452 -0.276061  4.064538  2.422861      1\n",
      "11167  0.127882 -0.271133 -0.501468  1.577176  5.298328      1\n",
      "11168  1.468039 -0.297675 -0.501468  1.240886  2.532568      1\n",
      "11169  0.188182 -0.368452  0.310000  2.119796  0.617302      1\n",
      "11170  0.111452 -0.394994 -0.366224  1.346372  2.661174      1\n",
      "11171  0.275584 -0.279980 -0.456387  2.130345  6.272128      1\n",
      "11172  0.543378  0.188921 -0.501468  1.578864  7.750705      1\n",
      "11173  2.015824  0.153533 -0.321142  2.192371 -0.377866      1\n",
      "11174  1.021715 -0.271133 -0.411305  5.478473 -0.377866      1\n",
      "11175  0.192247 -0.200356 -0.230979  1.200380  2.262087      1\n",
      "11176  0.723093 -0.195932 -0.321142  4.064538  2.422861      1\n",
      "11177  2.319189  0.728601 -0.501468 -0.859553 -0.377866      1\n",
      "11178 -0.250012 -0.377300 -0.321142  1.269157  3.652984      1\n",
      "11179  0.281343 -0.417112 -0.366224  0.851010  2.789649      1\n",
      "11180  1.204988  1.763724 -0.501468  1.562408  6.489072      1\n",
      "11181  0.736644 -0.222474 -0.050653  1.509665  0.539269      1\n",
      "11182  0.177003 -0.191508 -0.501468  1.578864  7.750705      1\n",
      "\n",
      "[11183 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "data_set = pd.read_csv('mammography.csv')\n",
    "# type(data_set)\n",
    "data_set = data_set.drop('X6',1)\n",
    "print (data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.230020</td>\n",
       "      <td>5.072578</td>\n",
       "      <td>-0.276061</td>\n",
       "      <td>0.832444</td>\n",
       "      <td>-0.377866</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.155491</td>\n",
       "      <td>-0.169390</td>\n",
       "      <td>0.670652</td>\n",
       "      <td>-0.859553</td>\n",
       "      <td>-0.377866</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.784415</td>\n",
       "      <td>-0.443654</td>\n",
       "      <td>5.674705</td>\n",
       "      <td>-0.859553</td>\n",
       "      <td>-0.377866</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.546088</td>\n",
       "      <td>0.131415</td>\n",
       "      <td>-0.456387</td>\n",
       "      <td>-0.859553</td>\n",
       "      <td>-0.377866</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.102987</td>\n",
       "      <td>-0.394994</td>\n",
       "      <td>-0.140816</td>\n",
       "      <td>0.979703</td>\n",
       "      <td>-0.377866</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.180395</td>\n",
       "      <td>-0.381723</td>\n",
       "      <td>0.264918</td>\n",
       "      <td>0.772950</td>\n",
       "      <td>1.468981</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.068603</td>\n",
       "      <td>-0.346334</td>\n",
       "      <td>-0.185897</td>\n",
       "      <td>0.899111</td>\n",
       "      <td>1.743381</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.082492</td>\n",
       "      <td>-0.448077</td>\n",
       "      <td>0.896060</td>\n",
       "      <td>-0.859553</td>\n",
       "      <td>-0.377866</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.151600</td>\n",
       "      <td>-0.368452</td>\n",
       "      <td>0.625571</td>\n",
       "      <td>1.197426</td>\n",
       "      <td>-0.377866</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.081137</td>\n",
       "      <td>-0.324216</td>\n",
       "      <td>1.031305</td>\n",
       "      <td>1.171687</td>\n",
       "      <td>-0.377866</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.775094</td>\n",
       "      <td>-0.443654</td>\n",
       "      <td>-0.501468</td>\n",
       "      <td>-0.859553</td>\n",
       "      <td>-0.377866</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.537619</td>\n",
       "      <td>1.586780</td>\n",
       "      <td>-0.276061</td>\n",
       "      <td>2.375494</td>\n",
       "      <td>-0.377866</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.304077</td>\n",
       "      <td>1.060371</td>\n",
       "      <td>-0.366224</td>\n",
       "      <td>1.865364</td>\n",
       "      <td>-0.377866</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.386021</td>\n",
       "      <td>1.776995</td>\n",
       "      <td>-0.411305</td>\n",
       "      <td>0.769574</td>\n",
       "      <td>-0.377866</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.101124</td>\n",
       "      <td>-0.279980</td>\n",
       "      <td>-0.276061</td>\n",
       "      <td>-0.859553</td>\n",
       "      <td>-0.377866</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7.469616</td>\n",
       "      <td>-0.448077</td>\n",
       "      <td>-0.591631</td>\n",
       "      <td>-0.859553</td>\n",
       "      <td>-0.377866</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.815068</td>\n",
       "      <td>2.728069</td>\n",
       "      <td>-0.050653</td>\n",
       "      <td>0.629911</td>\n",
       "      <td>0.791016</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.764084</td>\n",
       "      <td>0.569351</td>\n",
       "      <td>-0.501468</td>\n",
       "      <td>1.378018</td>\n",
       "      <td>-0.377866</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.442261</td>\n",
       "      <td>-0.443654</td>\n",
       "      <td>1.437039</td>\n",
       "      <td>-0.194146</td>\n",
       "      <td>0.127044</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.601646</td>\n",
       "      <td>0.600316</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.885609</td>\n",
       "      <td>0.728063</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.145159</td>\n",
       "      <td>-0.173814</td>\n",
       "      <td>-0.185897</td>\n",
       "      <td>0.545100</td>\n",
       "      <td>-0.377866</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.295406</td>\n",
       "      <td>-0.412689</td>\n",
       "      <td>0.039510</td>\n",
       "      <td>-0.859553</td>\n",
       "      <td>-0.377866</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.222397</td>\n",
       "      <td>-0.209203</td>\n",
       "      <td>-0.095734</td>\n",
       "      <td>0.046784</td>\n",
       "      <td>-0.377866</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.604864</td>\n",
       "      <td>0.578198</td>\n",
       "      <td>0.084592</td>\n",
       "      <td>-0.859553</td>\n",
       "      <td>-0.377866</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-0.140252</td>\n",
       "      <td>-0.085342</td>\n",
       "      <td>0.850978</td>\n",
       "      <td>0.425268</td>\n",
       "      <td>0.740509</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>-0.182767</td>\n",
       "      <td>0.051790</td>\n",
       "      <td>0.355081</td>\n",
       "      <td>1.154388</td>\n",
       "      <td>0.626752</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.007112</td>\n",
       "      <td>-0.271133</td>\n",
       "      <td>0.580489</td>\n",
       "      <td>1.068733</td>\n",
       "      <td>-0.377866</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>-0.322677</td>\n",
       "      <td>-0.372876</td>\n",
       "      <td>1.932936</td>\n",
       "      <td>-0.859553</td>\n",
       "      <td>-0.377866</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.252717</td>\n",
       "      <td>0.184498</td>\n",
       "      <td>0.264918</td>\n",
       "      <td>0.602063</td>\n",
       "      <td>-0.377866</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>-0.184460</td>\n",
       "      <td>-0.372876</td>\n",
       "      <td>0.355081</td>\n",
       "      <td>1.239620</td>\n",
       "      <td>-0.377866</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11147</th>\n",
       "      <td>0.436328</td>\n",
       "      <td>-0.386147</td>\n",
       "      <td>-0.276061</td>\n",
       "      <td>0.840461</td>\n",
       "      <td>1.097551</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11148</th>\n",
       "      <td>-0.204956</td>\n",
       "      <td>-0.359605</td>\n",
       "      <td>0.129673</td>\n",
       "      <td>-0.859553</td>\n",
       "      <td>-0.377866</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11150</th>\n",
       "      <td>-0.435486</td>\n",
       "      <td>-0.425959</td>\n",
       "      <td>1.932936</td>\n",
       "      <td>-0.128745</td>\n",
       "      <td>0.108803</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11154</th>\n",
       "      <td>0.151934</td>\n",
       "      <td>-0.213626</td>\n",
       "      <td>-0.005571</td>\n",
       "      <td>0.423158</td>\n",
       "      <td>-0.377866</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11156</th>\n",
       "      <td>0.185303</td>\n",
       "      <td>0.945357</td>\n",
       "      <td>0.084592</td>\n",
       "      <td>0.837929</td>\n",
       "      <td>-0.377866</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11157</th>\n",
       "      <td>-0.012537</td>\n",
       "      <td>-0.421536</td>\n",
       "      <td>0.400163</td>\n",
       "      <td>1.218101</td>\n",
       "      <td>1.080463</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11158</th>\n",
       "      <td>1.241744</td>\n",
       "      <td>4.205552</td>\n",
       "      <td>-0.321142</td>\n",
       "      <td>1.365782</td>\n",
       "      <td>1.829349</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11159</th>\n",
       "      <td>0.754260</td>\n",
       "      <td>0.016401</td>\n",
       "      <td>0.084592</td>\n",
       "      <td>4.942182</td>\n",
       "      <td>1.421602</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11160</th>\n",
       "      <td>0.964125</td>\n",
       "      <td>-0.341911</td>\n",
       "      <td>-0.411305</td>\n",
       "      <td>1.574222</td>\n",
       "      <td>3.703261</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11162</th>\n",
       "      <td>0.602662</td>\n",
       "      <td>-0.076495</td>\n",
       "      <td>-0.456387</td>\n",
       "      <td>1.844688</td>\n",
       "      <td>3.068362</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11163</th>\n",
       "      <td>0.187674</td>\n",
       "      <td>-0.328640</td>\n",
       "      <td>-0.456387</td>\n",
       "      <td>1.405444</td>\n",
       "      <td>4.605053</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11164</th>\n",
       "      <td>0.202580</td>\n",
       "      <td>-0.412689</td>\n",
       "      <td>-0.321142</td>\n",
       "      <td>1.223586</td>\n",
       "      <td>2.964186</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11165</th>\n",
       "      <td>1.107254</td>\n",
       "      <td>-0.098613</td>\n",
       "      <td>-0.546550</td>\n",
       "      <td>1.709666</td>\n",
       "      <td>7.722192</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11166</th>\n",
       "      <td>0.560655</td>\n",
       "      <td>-0.368452</td>\n",
       "      <td>-0.276061</td>\n",
       "      <td>4.064538</td>\n",
       "      <td>2.422861</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11167</th>\n",
       "      <td>0.127882</td>\n",
       "      <td>-0.271133</td>\n",
       "      <td>-0.501468</td>\n",
       "      <td>1.577176</td>\n",
       "      <td>5.298328</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11168</th>\n",
       "      <td>1.468039</td>\n",
       "      <td>-0.297675</td>\n",
       "      <td>-0.501468</td>\n",
       "      <td>1.240886</td>\n",
       "      <td>2.532568</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11169</th>\n",
       "      <td>0.188182</td>\n",
       "      <td>-0.368452</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>2.119796</td>\n",
       "      <td>0.617302</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11170</th>\n",
       "      <td>0.111452</td>\n",
       "      <td>-0.394994</td>\n",
       "      <td>-0.366224</td>\n",
       "      <td>1.346372</td>\n",
       "      <td>2.661174</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11171</th>\n",
       "      <td>0.275584</td>\n",
       "      <td>-0.279980</td>\n",
       "      <td>-0.456387</td>\n",
       "      <td>2.130345</td>\n",
       "      <td>6.272128</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11172</th>\n",
       "      <td>0.543378</td>\n",
       "      <td>0.188921</td>\n",
       "      <td>-0.501468</td>\n",
       "      <td>1.578864</td>\n",
       "      <td>7.750705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11173</th>\n",
       "      <td>2.015824</td>\n",
       "      <td>0.153533</td>\n",
       "      <td>-0.321142</td>\n",
       "      <td>2.192371</td>\n",
       "      <td>-0.377866</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11174</th>\n",
       "      <td>1.021715</td>\n",
       "      <td>-0.271133</td>\n",
       "      <td>-0.411305</td>\n",
       "      <td>5.478473</td>\n",
       "      <td>-0.377866</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11175</th>\n",
       "      <td>0.192247</td>\n",
       "      <td>-0.200356</td>\n",
       "      <td>-0.230979</td>\n",
       "      <td>1.200380</td>\n",
       "      <td>2.262087</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11176</th>\n",
       "      <td>0.723093</td>\n",
       "      <td>-0.195932</td>\n",
       "      <td>-0.321142</td>\n",
       "      <td>4.064538</td>\n",
       "      <td>2.422861</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11177</th>\n",
       "      <td>2.319189</td>\n",
       "      <td>0.728601</td>\n",
       "      <td>-0.501468</td>\n",
       "      <td>-0.859553</td>\n",
       "      <td>-0.377866</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11178</th>\n",
       "      <td>-0.250012</td>\n",
       "      <td>-0.377300</td>\n",
       "      <td>-0.321142</td>\n",
       "      <td>1.269157</td>\n",
       "      <td>3.652984</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11179</th>\n",
       "      <td>0.281343</td>\n",
       "      <td>-0.417112</td>\n",
       "      <td>-0.366224</td>\n",
       "      <td>0.851010</td>\n",
       "      <td>2.789649</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11180</th>\n",
       "      <td>1.204988</td>\n",
       "      <td>1.763724</td>\n",
       "      <td>-0.501468</td>\n",
       "      <td>1.562408</td>\n",
       "      <td>6.489072</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11181</th>\n",
       "      <td>0.736644</td>\n",
       "      <td>-0.222474</td>\n",
       "      <td>-0.050653</td>\n",
       "      <td>1.509665</td>\n",
       "      <td>0.539269</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11182</th>\n",
       "      <td>0.177003</td>\n",
       "      <td>-0.191508</td>\n",
       "      <td>-0.501468</td>\n",
       "      <td>1.578864</td>\n",
       "      <td>7.750705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7845 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             X1        X2        X3        X4        X5  class\n",
       "0      0.230020  5.072578 -0.276061  0.832444 -0.377866     -1\n",
       "1      0.155491 -0.169390  0.670652 -0.859553 -0.377866     -1\n",
       "2     -0.784415 -0.443654  5.674705 -0.859553 -0.377866     -1\n",
       "3      0.546088  0.131415 -0.456387 -0.859553 -0.377866     -1\n",
       "4     -0.102987 -0.394994 -0.140816  0.979703 -0.377866     -1\n",
       "5     -0.180395 -0.381723  0.264918  0.772950  1.468981     -1\n",
       "6     -0.068603 -0.346334 -0.185897  0.899111  1.743381     -1\n",
       "7     -0.082492 -0.448077  0.896060 -0.859553 -0.377866     -1\n",
       "8     -0.151600 -0.368452  0.625571  1.197426 -0.377866     -1\n",
       "10    -0.081137 -0.324216  1.031305  1.171687 -0.377866     -1\n",
       "12     0.775094 -0.443654 -0.501468 -0.859553 -0.377866     -1\n",
       "13     0.537619  1.586780 -0.276061  2.375494 -0.377866     -1\n",
       "14     1.304077  1.060371 -0.366224  1.865364 -0.377866     -1\n",
       "15     0.386021  1.776995 -0.411305  0.769574 -0.377866     -1\n",
       "17    -0.101124 -0.279980 -0.276061 -0.859553 -0.377866     -1\n",
       "18     7.469616 -0.448077 -0.591631 -0.859553 -0.377866     -1\n",
       "20     0.815068  2.728069 -0.050653  0.629911  0.791016     -1\n",
       "21     0.764084  0.569351 -0.501468  1.378018 -0.377866     -1\n",
       "22    -0.442261 -0.443654  1.437039 -0.194146  0.127044     -1\n",
       "27     0.601646  0.600316  0.310000  0.885609  0.728063     -1\n",
       "28     0.145159 -0.173814 -0.185897  0.545100 -0.377866     -1\n",
       "29    -0.295406 -0.412689  0.039510 -0.859553 -0.377866     -1\n",
       "30     0.222397 -0.209203 -0.095734  0.046784 -0.377866     -1\n",
       "31     0.604864  0.578198  0.084592 -0.859553 -0.377866     -1\n",
       "32    -0.140252 -0.085342  0.850978  0.425268  0.740509     -1\n",
       "33    -0.182767  0.051790  0.355081  1.154388  0.626752     -1\n",
       "35     0.007112 -0.271133  0.580489  1.068733 -0.377866     -1\n",
       "36    -0.322677 -0.372876  1.932936 -0.859553 -0.377866     -1\n",
       "38     0.252717  0.184498  0.264918  0.602063 -0.377866     -1\n",
       "41    -0.184460 -0.372876  0.355081  1.239620 -0.377866     -1\n",
       "...         ...       ...       ...       ...       ...    ...\n",
       "11147  0.436328 -0.386147 -0.276061  0.840461  1.097551     -1\n",
       "11148 -0.204956 -0.359605  0.129673 -0.859553 -0.377866     -1\n",
       "11150 -0.435486 -0.425959  1.932936 -0.128745  0.108803     -1\n",
       "11154  0.151934 -0.213626 -0.005571  0.423158 -0.377866     -1\n",
       "11156  0.185303  0.945357  0.084592  0.837929 -0.377866     -1\n",
       "11157 -0.012537 -0.421536  0.400163  1.218101  1.080463      1\n",
       "11158  1.241744  4.205552 -0.321142  1.365782  1.829349      1\n",
       "11159  0.754260  0.016401  0.084592  4.942182  1.421602      1\n",
       "11160  0.964125 -0.341911 -0.411305  1.574222  3.703261      1\n",
       "11162  0.602662 -0.076495 -0.456387  1.844688  3.068362      1\n",
       "11163  0.187674 -0.328640 -0.456387  1.405444  4.605053      1\n",
       "11164  0.202580 -0.412689 -0.321142  1.223586  2.964186      1\n",
       "11165  1.107254 -0.098613 -0.546550  1.709666  7.722192      1\n",
       "11166  0.560655 -0.368452 -0.276061  4.064538  2.422861      1\n",
       "11167  0.127882 -0.271133 -0.501468  1.577176  5.298328      1\n",
       "11168  1.468039 -0.297675 -0.501468  1.240886  2.532568      1\n",
       "11169  0.188182 -0.368452  0.310000  2.119796  0.617302      1\n",
       "11170  0.111452 -0.394994 -0.366224  1.346372  2.661174      1\n",
       "11171  0.275584 -0.279980 -0.456387  2.130345  6.272128      1\n",
       "11172  0.543378  0.188921 -0.501468  1.578864  7.750705      1\n",
       "11173  2.015824  0.153533 -0.321142  2.192371 -0.377866      1\n",
       "11174  1.021715 -0.271133 -0.411305  5.478473 -0.377866      1\n",
       "11175  0.192247 -0.200356 -0.230979  1.200380  2.262087      1\n",
       "11176  0.723093 -0.195932 -0.321142  4.064538  2.422861      1\n",
       "11177  2.319189  0.728601 -0.501468 -0.859553 -0.377866      1\n",
       "11178 -0.250012 -0.377300 -0.321142  1.269157  3.652984      1\n",
       "11179  0.281343 -0.417112 -0.366224  0.851010  2.789649      1\n",
       "11180  1.204988  1.763724 -0.501468  1.562408  6.489072      1\n",
       "11181  0.736644 -0.222474 -0.050653  1.509665  0.539269      1\n",
       "11182  0.177003 -0.191508 -0.501468  1.578864  7.750705      1\n",
       "\n",
       "[7845 rows x 6 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set.drop_duplicates(keep=False,inplace=True)  # Remove exemplos repetidos\n",
    "data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.230020</td>\n",
       "      <td>5.072578</td>\n",
       "      <td>-0.276061</td>\n",
       "      <td>0.832444</td>\n",
       "      <td>-0.377866</td>\n",
       "      <td>0.480322</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.155491</td>\n",
       "      <td>-0.169390</td>\n",
       "      <td>0.670652</td>\n",
       "      <td>-0.859553</td>\n",
       "      <td>-0.377866</td>\n",
       "      <td>-0.945723</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.784415</td>\n",
       "      <td>-0.443654</td>\n",
       "      <td>5.674705</td>\n",
       "      <td>-0.859553</td>\n",
       "      <td>-0.377866</td>\n",
       "      <td>-0.945723</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.546088</td>\n",
       "      <td>0.131415</td>\n",
       "      <td>-0.456387</td>\n",
       "      <td>-0.859553</td>\n",
       "      <td>-0.377866</td>\n",
       "      <td>-0.945723</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.102987</td>\n",
       "      <td>-0.394994</td>\n",
       "      <td>-0.140816</td>\n",
       "      <td>0.979703</td>\n",
       "      <td>-0.377866</td>\n",
       "      <td>1.013566</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         X1        X2        X3        X4        X5        X6  class\n",
       "0  0.230020  5.072578 -0.276061  0.832444 -0.377866  0.480322     -1\n",
       "1  0.155491 -0.169390  0.670652 -0.859553 -0.377866 -0.945723     -1\n",
       "2 -0.784415 -0.443654  5.674705 -0.859553 -0.377866 -0.945723     -1\n",
       "3  0.546088  0.131415 -0.456387 -0.859553 -0.377866 -0.945723     -1\n",
       "4 -0.102987 -0.394994 -0.140816  0.979703 -0.377866  1.013566     -1"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imprime as 5 primeiras linhas do data set\n",
    "data_set.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7845.000000</td>\n",
       "      <td>7845.000000</td>\n",
       "      <td>7845.000000</td>\n",
       "      <td>7845.000000</td>\n",
       "      <td>7845.000000</td>\n",
       "      <td>7845.000000</td>\n",
       "      <td>7845.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.333764</td>\n",
       "      <td>0.200042</td>\n",
       "      <td>0.251736</td>\n",
       "      <td>0.365734</td>\n",
       "      <td>0.160780</td>\n",
       "      <td>0.402400</td>\n",
       "      <td>-0.935500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.025813</td>\n",
       "      <td>1.136427</td>\n",
       "      <td>1.101461</td>\n",
       "      <td>0.988616</td>\n",
       "      <td>1.157123</td>\n",
       "      <td>0.939678</td>\n",
       "      <td>0.353348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.784415</td>\n",
       "      <td>-0.452501</td>\n",
       "      <td>-0.591631</td>\n",
       "      <td>-0.859553</td>\n",
       "      <td>-0.377866</td>\n",
       "      <td>-0.945723</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.145333</td>\n",
       "      <td>-0.408265</td>\n",
       "      <td>-0.276061</td>\n",
       "      <td>-0.859553</td>\n",
       "      <td>-0.377866</td>\n",
       "      <td>-0.945723</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.111790</td>\n",
       "      <td>-0.271133</td>\n",
       "      <td>-0.005571</td>\n",
       "      <td>0.550163</td>\n",
       "      <td>-0.377866</td>\n",
       "      <td>0.845975</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.508993</td>\n",
       "      <td>0.219887</td>\n",
       "      <td>0.400163</td>\n",
       "      <td>1.027382</td>\n",
       "      <td>0.387549</td>\n",
       "      <td>1.132403</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>31.508443</td>\n",
       "      <td>5.085849</td>\n",
       "      <td>29.477769</td>\n",
       "      <td>9.591164</td>\n",
       "      <td>23.617122</td>\n",
       "      <td>1.949027</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                X1           X2           X3           X4           X5  \\\n",
       "count  7845.000000  7845.000000  7845.000000  7845.000000  7845.000000   \n",
       "mean      0.333764     0.200042     0.251736     0.365734     0.160780   \n",
       "std       1.025813     1.136427     1.101461     0.988616     1.157123   \n",
       "min      -0.784415    -0.452501    -0.591631    -0.859553    -0.377866   \n",
       "25%      -0.145333    -0.408265    -0.276061    -0.859553    -0.377866   \n",
       "50%       0.111790    -0.271133    -0.005571     0.550163    -0.377866   \n",
       "75%       0.508993     0.219887     0.400163     1.027382     0.387549   \n",
       "max      31.508443     5.085849    29.477769     9.591164    23.617122   \n",
       "\n",
       "                X6        class  \n",
       "count  7845.000000  7845.000000  \n",
       "mean      0.402400    -0.935500  \n",
       "std       0.939678     0.353348  \n",
       "min      -0.945723    -1.000000  \n",
       "25%      -0.945723    -1.000000  \n",
       "50%       0.845975    -1.000000  \n",
       "75%       1.132403    -1.000000  \n",
       "max       1.949027     1.000000  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estatísticas sobre as variáveis\n",
    "data_set.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos separar o data set em atributos dependentes (X = features) e independentes (y = classe). No caso do `mammography` a classe majoritária está codificada como -1 e a classe minoritária está codificada como 1. Para treinar nossa rede neural precisamos que os valores de classe sejam 0 e 1 (restrição da biblioteca `keras`), assim modificamos a codificação da majoritária para 0.\n",
    "\n",
    "Perceba que esse pré-processamento varia de data set para data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Também convertemos os dados para arrays ao invés de DataFrames\n",
    "X = data_set.iloc[:, :-1].values\n",
    "y = data_set.iloc[:, -1].values\n",
    "y = np.where(y == -1, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divisão dos Dados em Treino, Validação, e Teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui dividimos o data set em treino, validação e teste de maneira estratificada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Treino: 50%, Validação: 25%, Teste: 25%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/4, \n",
    "                                                    random_state=42, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=1/3, \n",
    "                                                  random_state=42, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KFold(n_splits=10, random_state=None, shuffle=True)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Treinamento com divisão dos dados em kfolds\n",
    "data = data_set.iloc[:,:].values\n",
    "# data\n",
    "from sklearn.model_selection import KFold\n",
    "kfolds = KFold(n_splits=10, shuffle=True)\n",
    "# kfolds\n",
    "kfolds.get_n_splits(data)\n",
    "kfolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "785 7060\n",
      "785 7060\n",
      "785 7060\n",
      "785 7060\n",
      "785 7060\n",
      "784 7061\n",
      "784 7061\n",
      "784 7061\n",
      "784 7061\n",
      "784 7061\n"
     ]
    }
   ],
   "source": [
    "#metodo kfolds\n",
    "for train_index, test_index in kfolds.split(data):\n",
    "#     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    print (len(X_test), len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling dos Dados e Normalização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para testar o comportamento da rede com diferentes funções de sampling, as mesmas devem ser implementadas e aplicadas ao conjunto de treinamento antes da normalização dos dados (você também pode investigar qual o efeito de aplicar o sampling após a normalização)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TO DO -- Implementar as funções de sampling a serem utilizadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É importante lembrar de normalizar os dados. A classe `StandardScaler` centraliza as variáveis e transforma as features para terem variância unitária. Você pode testar outras opções como o `MinMaxScaler`.\n",
    "\n",
    "Todas as alternativas estão disponíveis em:\n",
    "http://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição e Treino da Rede"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui definimos a arquitetura da nossa rede neural e treinamos ela.\n",
    "\n",
    "No presente exemplo a rede possui apenas uma camada escondida. O código é bem intuitivo e a adição de novas camadas pode ser feita através da função `add`.\n",
    "\n",
    "Para treinar a rede várias funções de otimização estão disponíveis. \n",
    "\n",
    "Confira os exemplos em: https://keras.io/optimizers/\n",
    "\n",
    "O treinamento da rede pode ser interrompido baseado na performance dela em um conjunto de validação através de callbacks.\n",
    "\n",
    "Confira a documentação da classe `EarlyStopping`: https://keras.io/callbacks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3922 samples, validate on 1961 samples\n",
      "Epoch 1/150\n",
      "3922/3922 [==============================] - 1s - loss: 0.0248 - val_loss: 0.0219\n",
      "Epoch 2/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0219 - val_loss: 0.0207\n",
      "Epoch 3/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0210 - val_loss: 0.0190\n",
      "Epoch 4/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0206 - val_loss: 0.0192\n",
      "Epoch 5/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0197 - val_loss: 0.0186\n",
      "Epoch 6/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0192 - val_loss: 0.0179\n",
      "Epoch 7/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0193 - val_loss: 0.0177\n",
      "Epoch 8/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0190 - val_loss: 0.0187\n",
      "Epoch 9/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0183 - val_loss: 0.0172\n",
      "Epoch 10/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0184 - val_loss: 0.0176\n",
      "Epoch 11/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0181 - val_loss: 0.0176\n",
      "Epoch 12/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0179 - val_loss: 0.0171\n",
      "Epoch 13/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0179 - val_loss: 0.0170\n",
      "Epoch 14/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0174 - val_loss: 0.0168\n",
      "Epoch 15/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0176 - val_loss: 0.0169\n",
      "Epoch 16/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0176 - val_loss: 0.0169\n",
      "Epoch 17/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0172 - val_loss: 0.0168\n",
      "Epoch 18/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0168 - val_loss: 0.0166\n",
      "Epoch 19/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0171 - val_loss: 0.0168\n",
      "Epoch 20/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0167 - val_loss: 0.0167\n",
      "Epoch 21/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0167 - val_loss: 0.0169\n",
      "Epoch 22/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0169 - val_loss: 0.0169\n",
      "Epoch 23/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0164 - val_loss: 0.0175\n",
      "Epoch 24/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0178 - val_loss: 0.0162\n",
      "Epoch 25/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0162 - val_loss: 0.0162\n",
      "Epoch 26/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0164 - val_loss: 0.0162\n",
      "Epoch 27/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0159 - val_loss: 0.0161\n",
      "Epoch 28/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0161 - val_loss: 0.0159\n",
      "Epoch 29/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0157 - val_loss: 0.0168\n",
      "Epoch 30/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0158 - val_loss: 0.0161\n",
      "Epoch 31/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0160 - val_loss: 0.0174\n",
      "Epoch 32/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0162 - val_loss: 0.0163\n",
      "Epoch 33/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0155 - val_loss: 0.0160\n",
      "Epoch 34/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0158 - val_loss: 0.0161\n"
     ]
    }
   ],
   "source": [
    "# Aqui criamos o esboço da rede.\n",
    "classifier = Sequential()\n",
    "\n",
    "# Agora adicionamos a primeira camada escondida contendo 16 neurônios e função de ativação\n",
    "# tangente hiperbólica. Por ser a primeira camada adicionada à rede, precisamos especificar\n",
    "# a dimensão de entrada (número de features do data set), que no caso do mammography são 6.\n",
    "classifier.add(Dense(16, activation='relu', input_dim=5))\n",
    "\n",
    "classifier.add(Dense(20, activation='relu',))\n",
    "\n",
    "classifier.add(Dense(10, activation='relu',))\n",
    "\n",
    "# classifier.add(Dense(30, activation='relu',))\n",
    "\n",
    "classifier.add(Dense(15, activation='relu',))\n",
    "\n",
    "classifier.add(Dense(8, activation='relu',))\n",
    "\n",
    "# Em seguida adicionamos a camada de saída. Como nosso problema é binário só precisamos de\n",
    "# 1 neurônio com função de ativação sigmoidal. A partir da segunda camada adicionada keras já\n",
    "# consegue inferir o número de neurônios de entrada (16) e nós não precisamos mais especificar.\n",
    "classifier.add(Dense(1, activation='relu'))\n",
    "\n",
    "# Por fim compilamos o modelo especificando um otimizador, a função de custo, e opcionalmente\n",
    "# métricas para serem observadas durante treinamento.\n",
    "classifier.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "# Para treinar a rede passamos o conjunto de treinamento e especificamos o tamanho do mini-batch,\n",
    "# o número máximo de épocas, e opcionalmente callbacks. No presente exemplo utilizamos early\n",
    "# stopping para interromper o treinamento caso a performance não melhore em um conjunto de validação.\n",
    "history = classifier.fit(X_train, y_train, batch_size=64, epochs=150, \n",
    "                         callbacks=[early_stopping], validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3922 samples, validate on 1961 samples\n",
      "Epoch 1/150\n",
      "3922/3922 [==============================] - 1s - loss: 0.0246 - val_loss: 0.0219\n",
      "Epoch 2/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0212 - val_loss: 0.0205\n",
      "Epoch 3/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0207 - val_loss: 0.0188\n",
      "Epoch 4/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0195 - val_loss: 0.0193\n",
      "Epoch 5/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0188 - val_loss: 0.0237\n",
      "Epoch 6/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0192 - val_loss: 0.0169\n",
      "Epoch 7/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0179 - val_loss: 0.0172\n",
      "Epoch 8/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0175 - val_loss: 0.0170\n",
      "Epoch 9/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0174 - val_loss: 0.0171\n",
      "Epoch 10/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0167 - val_loss: 0.0173\n",
      "Epoch 11/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0165 - val_loss: 0.0186\n",
      "Epoch 12/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0167 - val_loss: 0.0171\n"
     ]
    }
   ],
   "source": [
    "# Aqui criamos o esboço da rede.\n",
    "classifier = Sequential()\n",
    "\n",
    "# Agora adicionamos a primeira camada escondida contendo 16 neurônios e função de ativação\n",
    "# tangente hiperbólica. Por ser a primeira camada adicionada à rede, precisamos especificar\n",
    "# a dimensão de entrada (número de features do data set), que no caso do mammography são 6.\n",
    "classifier.add(Dense(50, activation='relu', input_dim=5))\n",
    "\n",
    "classifier.add(Dense(40, activation='relu',))\n",
    "\n",
    "classifier.add(Dense(30, activation='relu',))\n",
    "\n",
    "# classifier.add(Dense(30, activation='relu',))\n",
    "\n",
    "classifier.add(Dense(15, activation='relu',))\n",
    "\n",
    "classifier.add(Dense(8, activation='relu',))\n",
    "\n",
    "# Em seguida adicionamos a camada de saída. Como nosso problema é binário só precisamos de\n",
    "# 1 neurônio com função de ativação sigmoidal. A partir da segunda camada adicionada keras já\n",
    "# consegue inferir o número de neurônios de entrada (16) e nós não precisamos mais especificar.\n",
    "classifier.add(Dense(1, activation='relu'))\n",
    "\n",
    "# Por fim compilamos o modelo especificando um otimizador, a função de custo, e opcionalmente\n",
    "# métricas para serem observadas durante treinamento.\n",
    "classifier.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "# Para treinar a rede passamos o conjunto de treinamento e especificamos o tamanho do mini-batch,\n",
    "# o número máximo de épocas, e opcionalmente callbacks. No presente exemplo utilizamos early\n",
    "# stopping para interromper o treinamento caso a performance não melhore em um conjunto de validação.\n",
    "history = classifier.fit(X_train, y_train, batch_size=64, epochs=150, \n",
    "                         callbacks=[early_stopping], validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3922 samples, validate on 1961 samples\n",
      "Epoch 1/150\n",
      "3922/3922 [==============================] - 1s - loss: 0.0324 - val_loss: 0.0321\n",
      "Epoch 2/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0324 - val_loss: 0.0321\n",
      "Epoch 3/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0324 - val_loss: 0.0321\n",
      "Epoch 4/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0324 - val_loss: 0.0321\n",
      "Epoch 5/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0324 - val_loss: 0.0321\n",
      "Epoch 6/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0324 - val_loss: 0.0321\n",
      "Epoch 7/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0324 - val_loss: 0.0321\n"
     ]
    }
   ],
   "source": [
    "# Aqui criamos o esboço da rede.\n",
    "classifier = Sequential()\n",
    "\n",
    "# Agora adicionamos a primeira camada escondida contendo 16 neurônios e função de ativação\n",
    "# tangente hiperbólica. Por ser a primeira camada adicionada à rede, precisamos especificar\n",
    "# a dimensão de entrada (número de features do data set), que no caso do mammography são 6.\n",
    "classifier.add(Dense(100, activation='relu', input_dim=5))\n",
    "\n",
    "classifier.add(Dense(110, activation='relu',))\n",
    "\n",
    "classifier.add(Dense(80, activation='relu',))\n",
    "\n",
    "classifier.add(Dense(90, activation='relu',))\n",
    "\n",
    "classifier.add(Dense(70, activation='relu',))\n",
    "\n",
    "classifier.add(Dense(50, activation='relu',))\n",
    "\n",
    "classifier.add(Dense(70, activation='relu',))\n",
    "\n",
    "classifier.add(Dense(30, activation='relu',))\n",
    "\n",
    "classifier.add(Dense(20, activation='relu',))\n",
    "\n",
    "classifier.add(Dense(10, activation='relu',))\n",
    "\n",
    "# Em seguida adicionamos a camada de saída. Como nosso problema é binário só precisamos de\n",
    "# 1 neurônio com função de ativação sigmoidal. A partir da segunda camada adicionada keras já\n",
    "# consegue inferir o número de neurônios de entrada (16) e nós não precisamos mais especificar.\n",
    "classifier.add(Dense(1, activation='relu'))\n",
    "\n",
    "# Por fim compilamos o modelo especificando um otimizador, a função de custo, e opcionalmente\n",
    "# métricas para serem observadas durante treinamento.\n",
    "classifier.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "# Para treinar a rede passamos o conjunto de treinamento e especificamos o tamanho do mini-batch,\n",
    "# o número máximo de épocas, e opcionalmente callbacks. No presente exemplo utilizamos early\n",
    "# stopping para interromper o treinamento caso a performance não melhore em um conjunto de validação.\n",
    "history = classifier.fit(X_train, y_train, batch_size=64, epochs=150, \n",
    "                         callbacks=[early_stopping], validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3922 samples, validate on 1961 samples\n",
      "Epoch 1/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0248 - val_loss: 0.0219\n",
      "Epoch 2/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0211 - val_loss: 0.0199\n",
      "Epoch 3/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0205 - val_loss: 0.0202\n",
      "Epoch 4/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0200 - val_loss: 0.0188\n",
      "Epoch 5/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0195 - val_loss: 0.0193\n",
      "Epoch 6/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0192 - val_loss: 0.0180\n",
      "Epoch 7/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0188 - val_loss: 0.0176\n",
      "Epoch 8/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0183 - val_loss: 0.0178\n",
      "Epoch 9/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0184 - val_loss: 0.0167\n",
      "Epoch 10/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0183 - val_loss: 0.0175\n",
      "Epoch 11/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0186 - val_loss: 0.0171\n",
      "Epoch 12/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0173 - val_loss: 0.0165\n",
      "Epoch 13/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0170 - val_loss: 0.0172\n",
      "Epoch 14/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0174 - val_loss: 0.0159\n",
      "Epoch 15/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0174 - val_loss: 0.0155\n",
      "Epoch 16/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0167 - val_loss: 0.0155\n",
      "Epoch 17/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0162 - val_loss: 0.0151\n",
      "Epoch 18/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0162 - val_loss: 0.0155\n",
      "Epoch 19/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0164 - val_loss: 0.0157\n",
      "Epoch 20/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0158 - val_loss: 0.0149\n",
      "Epoch 21/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0158 - val_loss: 0.0154\n",
      "Epoch 22/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0169 - val_loss: 0.0156\n",
      "Epoch 23/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0162 - val_loss: 0.0158\n",
      "Epoch 24/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0161 - val_loss: 0.0164\n",
      "Epoch 25/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0158 - val_loss: 0.0151\n",
      "Epoch 26/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0157 - val_loss: 0.0147\n",
      "Epoch 27/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0156 - val_loss: 0.0149\n",
      "Epoch 28/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0150 - val_loss: 0.0150\n",
      "Epoch 29/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0152 - val_loss: 0.0161\n",
      "Epoch 30/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0156 - val_loss: 0.0146\n",
      "Epoch 31/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0149 - val_loss: 0.0142\n",
      "Epoch 32/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0149 - val_loss: 0.0149\n",
      "Epoch 33/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0156 - val_loss: 0.0141\n",
      "Epoch 34/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0147 - val_loss: 0.0141\n",
      "Epoch 35/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0146 - val_loss: 0.0142\n",
      "Epoch 36/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0149 - val_loss: 0.0146\n",
      "Epoch 37/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0145 - val_loss: 0.0138\n",
      "Epoch 38/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0143 - val_loss: 0.0136\n",
      "Epoch 39/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0145 - val_loss: 0.0164\n",
      "Epoch 40/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0145 - val_loss: 0.0136\n",
      "Epoch 41/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0141 - val_loss: 0.0145\n",
      "Epoch 42/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0140 - val_loss: 0.0137\n",
      "Epoch 43/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0140 - val_loss: 0.0151\n",
      "Epoch 44/150\n",
      "3922/3922 [==============================] - 0s - loss: 0.0144 - val_loss: 0.0140\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "# Para treinar a rede passamos o conjunto de treinamento e especificamos o tamanho do mini-batch,\n",
    "# o número máximo de épocas, e opcionalmente callbacks. No presente exemplo utilizamos early\n",
    "# stopping para interromper o treinamento caso a performance não melhore em um conjunto de validação.\n",
    "history = classifier.fit(X_train, y_train, batch_size=64, epochs=150, \n",
    "                         callbacks=[early_stopping], validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utilizado para salvar os pesos da rede\n",
    "classifier.save_weights(\"pesos.h5\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algumas funções auxiliares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_final_losses(history):\n",
    "    \"\"\"Função para extrair o melhor loss de treino e validação.\n",
    "    \n",
    "    Argumento(s):\n",
    "    history -- Objeto retornado pela função fit do keras.\n",
    "    \n",
    "    Retorno:\n",
    "    Dicionário contendo o melhor loss de treino e de validação baseado \n",
    "    no menor loss de validação.\n",
    "    \"\"\"\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    idx_min_val_loss = np.argmin(val_loss)\n",
    "    return {'train_loss': train_loss[idx_min_val_loss], 'val_loss': val_loss[idx_min_val_loss]}\n",
    "\n",
    "def plot_training_error_curves(history):\n",
    "    \"\"\"Função para plotar as curvas de erro do treinamento da rede neural.\n",
    "    \n",
    "    Argumento(s):\n",
    "    history -- Objeto retornado pela função fit do keras.\n",
    "    \n",
    "    Retorno:\n",
    "    A função gera o gráfico do treino da rede e retorna None.\n",
    "    \"\"\"\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(train_loss, label='Train')\n",
    "    ax.plot(val_loss, label='Validation')\n",
    "    ax.set(title='Training and Validation Error Curves', xlabel='Epochs', ylabel='Loss (MSE)')\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overriden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_training_error_curves(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predições no Conjunto de Teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora utilizamos a nossa rede para fazer predições no conjunto de teste e computar métricas de desempenho.\n",
    "\n",
    "Além das métricas utilizadas aqui, mais métricas de desempenho podem ser encontradas em: http://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusão\n",
      "[[1880   19]\n",
      " [  36   28]]\n",
      "\n",
      "Train Loss:       0.0143\n",
      "Validation Loss:  0.0171\n",
      "Accuracy:         0.9720\n",
      "Recall:           0.4375\n",
      "Precision:        0.5957\n",
      "F1:               0.5045\n",
      "AUROC:            0.9044\n"
     ]
    }
   ],
   "source": [
    "## Fazer predições no conjunto de teste\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred_class = classifier.predict_classes(X_test, verbose=0)\n",
    "\n",
    "## Matriz de confusão\n",
    "print('Matriz de confusão')\n",
    "print(confusion_matrix(y_test, y_pred_class))\n",
    "\n",
    "## Computar métricas de desempenho\n",
    "losses = extract_final_losses(history)\n",
    "print()\n",
    "print(\"{metric:<18}{value:.4f}\".format(metric=\"Train Loss:\", value=losses['train_loss']))\n",
    "print(\"{metric:<18}{value:.4f}\".format(metric=\"Validation Loss:\", value=losses['val_loss']))\n",
    "print(\"{metric:<18}{value:.4f}\".format(metric=\"Accuracy:\", value=accuracy_score(y_test, y_pred_class)))\n",
    "print(\"{metric:<18}{value:.4f}\".format(metric=\"Recall:\", value=recall_score(y_test, y_pred_class)))\n",
    "print(\"{metric:<18}{value:.4f}\".format(metric=\"Precision:\", value=precision_score(y_test, y_pred_class)))\n",
    "print(\"{metric:<18}{value:.4f}\".format(metric=\"F1:\", value=f1_score(y_test, y_pred_class)))\n",
    "print(\"{metric:<18}{value:.4f}\".format(metric=\"AUROC:\", value=roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
